{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS  = The probability that an employee is a smoker given that he/she uses the health insurance plan can be calculated using Bayes' theorem:\n",
    "P r‚à£uses insurance)= \n",
    "P(uses insurance)\n",
    "P(uses insurance‚à£smoker)‚ãÖP(smoker)\n",
    "‚Äã\n",
    " \n",
    "Given that 40% of the employees who use the plan are smokers, and 70% of employees use the plan, we can calculate:\n",
    "ùëÉ\n",
    "(\n",
    "smoker\n",
    "‚à£\n",
    "uses insurance\n",
    ")\n",
    "=\n",
    "0.40\n",
    "‚ãÖ\n",
    "0.70\n",
    "0.70\n",
    "=\n",
    "0.40\n",
    "P(smoker‚à£uses insurance)= \n",
    "0.70\n",
    "0.40‚ãÖ0.70\n",
    "‚Äã\n",
    " =0.40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = Bernoulli Naive Bayes assumes binary feature vectors, where each feature represents the presence or absence of a particular term. Multinomial Naive Bayes, on the other hand, is used when features represent counts or frequencies of occurrences of each term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = Bernoulli Naive Bayes handles missing values by assuming that missing values are indicative of the absence of the corresponding feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = Yes, Gaussian Naive Bayes can be used for multi-class classification. It models each class's likelihood as a Gaussian distribution, making it suitable for continuous features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score\n",
    "Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?\n",
    "Conclusion:\n",
    "Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = Download the \"Spambase Data Set\" from the UCI Machine Learning Repository.\n",
    "Implement Bernoulli, Multinomial, and Gaussian Naive Bayes classifiers using scikit-learn.\n",
    "Evaluate the performance of each classifier using 10-fold cross-validation.\n",
    "Report accuracy, precision, recall, and F1 score for each classifier.\n",
    "Discuss the results obtained, including which variant performed the best and any observed limitations of Naive Bayes.\n",
    "Conclusion:\n",
    "\n",
    "Summarize the findings from the evaluation of different Naive Bayes variants.\n",
    "Provide suggestions for future work, such as exploring ensemble methods or feature engineering techniques to improve classification performance.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
